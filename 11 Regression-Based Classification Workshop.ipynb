{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expensive-lover",
   "metadata": {},
   "source": [
    "Li Ju: Cantonese dim sum; Watch TV Series\n",
    "Chauguk Lee:Sushi; Play Tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-unknown",
   "metadata": {},
   "source": [
    "## Workshop - Regression-Based Classification\n",
    "\n",
    "Does `statsmodels` marginal effect use the average of covariates or the average predicted values? \n",
    "- Use the class data.\n",
    "- Show your work.\n",
    "\n",
    "Load the necessary packages and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innovative-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'axes.titlesize': 24,\n",
    "             'axes.labelsize': 20,\n",
    "             'xtick.labelsize': 12,\n",
    "             'ytick.labelsize': 12,\n",
    "             'figure.figsize': (8, 4.5)})\n",
    "sns.set_style(\"white\") # for plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "racial-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('class_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['urate_bin', 'year']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df.year, drop_first = True)    \n",
    "])\n",
    "y = df_prepped['pos_net_jobs'].astype(float)\n",
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-terrorism",
   "metadata": {},
   "source": [
    "Fit a logistic regression using either `sm.Logit()` or `smf.logit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "powerful-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670597\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "fit_logit = sm.Logit(y_train, x_train[['const','pct_d_rgdp', 'estabs_exit_rate']]).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-therapy",
   "metadata": {},
   "source": [
    "Get the marginal effects (`.get_margeff()`). Print the summary (`.summary()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "three-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>pos_net_jobs</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>            <td>dydx</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>               <td>overall</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <th></th>            <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>       <td>    0.0057</td> <td>    0.000</td> <td>   17.597</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th> <td>   -0.0280</td> <td>    0.001</td> <td>  -26.347</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:           pos_net_jobs\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "====================================================================================\n",
       "                      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           0.0057      0.000     17.597      0.000       0.005       0.006\n",
       "estabs_exit_rate    -0.0280      0.001    -26.347      0.000      -0.030      -0.026\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adopted-enterprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const               1.238731\n",
       "pct_d_rgdp          0.023849\n",
       "estabs_exit_rate   -0.117092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-smoke",
   "metadata": {},
   "source": [
    "***\n",
    "# Covariate Averages\n",
    "$$\n",
    "\\frac{\\partial p(x_i)}{\\partial \\beta_1} \\approx \\frac{e^{\\hat{\\beta}_0 + \\bar{x}\\hat{\\beta}_1 + \\bar{x}\\hat{\\beta_2}}}{(1 + e^{\\hat{\\beta}_0 + \\bar{x}\\hat{\\beta}_1 + \\bar{x}\\hat{\\beta_2}})^2}\\hat{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "preliminary-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_values = fit_logit.params.values\n",
    "exp_ca_1 = np.exp(params_values[0] + \n",
    "                  params_values[1] * np.mean(x_train['pct_d_rgdp']) \n",
    "                  + params_values[2] * np.mean(x_train['pct_d_rgdp']))\n",
    "marginal_ca_1 = exp_ca_1*params_values[1]/(1+exp_ca_1)**2\n",
    "exp_ca_2 = np.exp(params_values[0] + \n",
    "                  params_values[1] * np.mean(x_train['estabs_exit_rate']) \n",
    "                  + params_values[2] * np.mean(x_train['estabs_exit_rate']))\n",
    "marginal_ca_2 = exp_ca_2*params_values[2]/(1+exp_ca_2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "previous-charter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004571176832974548\n",
      "-0.028056827483015245\n"
     ]
    }
   ],
   "source": [
    "print(marginal_ca_1)\n",
    "print(marginal_ca_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-objective",
   "metadata": {},
   "source": [
    "***\n",
    "# Predicted values Averages\n",
    "$$\n",
    "\\frac{\\partial p(x_i)}{\\partial \\beta_1} \\approx \\frac{1}{n} \\sum_{i=1}\n",
    "^n \\frac{e^{\\hat{y}_i}}{1 + e^{\\hat{y}_i}}\\hat{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "subtle-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_i = fit_logit.predict(x_test[['const','pct_d_rgdp', 'estabs_exit_rate']])\n",
    "marginal_pva_1 = np.mean(np.exp(y_i)*params_values[1]/(1 + np.exp(y_i)))\n",
    "marginal_pva_2 = np.mean(np.exp(y_i)*params_values[2]/(1 + np.exp(y_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "spoken-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01517294450030358\n",
      "-0.07449624730702548\n"
     ]
    }
   ],
   "source": [
    "print(marginal_pva_1)\n",
    "print(marginal_pva_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-housing",
   "metadata": {},
   "source": [
    "*** \n",
    "# Interpretation\n",
    "\n",
    "Interpret the marginal effect on one feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "rubber-sweet",
   "metadata": {},
   "source": [
    "An increase in GDP by one percentage point is associated with\n",
    "an increase in the probability of positive net job creation rate of 0.005. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
